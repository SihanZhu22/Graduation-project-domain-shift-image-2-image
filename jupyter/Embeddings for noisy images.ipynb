{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f32ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0d085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = [0,0.1,0.2,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f28560e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCityscapeDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, labels, noise_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#         self.image_dir = image_dir\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#         self.image_fns = os.listdir(image_dir)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#         self.label_model = label_model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m images\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class CityscapeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images, labels, noise_level = 0):\n",
    "#         self.image_dir = image_dir\n",
    "#         self.image_fns = os.listdir(image_dir)\n",
    "#         self.label_model = label_model\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.noise_level = noise_level\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "#         mean = 0\n",
    "#         var = 0.1\n",
    "#         sigma = var**0.5\n",
    "        if self.noise_level!=0:\n",
    "            image = image+(self.noise_level*np.random.normal(0, (image.max() - image.min()), image.shape)).astype(\"uint8\") # (mean, sigma, image_shape)\n",
    "#             gauss = np.random.normal(mean,sigma,image.shape).astype(\"uint8\")\n",
    "#             image = image+gauss\n",
    "        image = self.transform(image)\n",
    "        label = torch.from_numpy(label).long()\n",
    "        return image, label\n",
    "            # gaussian nosie\n",
    "            # sigma could be changed, leave it for now\n",
    "                # e.g.(image.max() - image.min())/6.\n",
    "#             print(image.max()) -255\n",
    "#             print(image.min()) -0\n",
    "#             print(image.dtype) -unint8 \n",
    "        \n",
    "    def transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) # normalize to control the \"dynamic range\" of activations of different layers\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f629ea",
   "metadata": {},
   "source": [
    "A function to transform original data to noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_one_domain(noise_level,original_dataset,mode = \"PCA\"):\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    if noise_level == 0:\n",
    "        dataset = original_dataset\n",
    "    else:\n",
    "        dataset = transform_dataset(original_dataset,noise_level=noise_level)\n",
    "\n",
    "    flat = np.reshape(dataset,(500, 256*256*3))\n",
    "    \n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(original_dataset,noise_level=0):\n",
    "    new_dataset = []\n",
    "    if noise_level == 0:\n",
    "        print(\"No transformation needed\")\n",
    "        return original_dataset\n",
    "    for image in original_dataset:\n",
    "        if noise_level!=0:\n",
    "            new_image = image+(noise_level*np.random.normal(0, (image.max() - image.min())/6., image.shape)).astype(\"uint8\") # (mean, sigma, image_shape)\n",
    "            new_dataset.append(new_image)\n",
    "    new_dataset = np.array(new_dataset)\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_list = [get_data_for_one_domain(noise_levels[i], original_dataset = X_test) for i in range(len(noise_levels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_array = np.array(input_image_list)\n",
    "input_image_array = input_image_array.reshape((input_image_array.shape)[0]*(input_image_array.shape)[1],(input_image_array.shape)[2])\n",
    "pca_50 = PCA(n_components = 50)\n",
    "pca_embedding = pca.fit_transform(input_image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f134b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_full = pd.DataFrame(embedding,columns=[\"tsne_1\",\"tsne_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a953bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
